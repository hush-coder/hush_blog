# ***AI-深度学习CNN***

# 摘要

# 目录

# 优缺

加了卷积层，防止参数爆炸

卷积层后面是池化层

# several question

## 升降维和1*1卷积

### 示例

以降维为例：

```cpp
// 第1步：理解特征图的形状
输入特征图形状：[C_in=256, H, W] = [256, 32, 32]

// 第2步：1×1卷积核的权重
1×1卷积核权重形状：[C_out=64, C_in=256, 1, 1] = [64, 256, 1, 1]
实际是：一个64×256的矩阵W，每个元素w_ij是一个标量

// 第3步：对每个位置独立计算
输入：一个256维向量 v = [v₁, v₂, ..., v₂₅₆]
权重矩阵：W (64×256)

计算：输出 = W × v  （其实是vᵀ × Wᵀ，但为了理解方便）

具体：
y₁ = w₁₁*v₁ + w₁₂*v₂ + ... + w₁,₂₅₆*v₂₅₆
y₂ = w₂₁*v₁ + w₂₂*v₂ + ... + w₂,₂₅₆*v₂₅₆
...
y₆₄ = w₆₄,₁*v₁ + w₆₄,₂*v₂ + ... + w₆₄,₂₅₆*v₂₅₆

输出：一个64维向量 [y₁, y₂, ..., y₆₄]
```

### 可视化

***比喻：256个专家意见 → 64个决策要点***

假设我们有256个专家，每个专家对某件事有个评分（0-10分）：

```
专家A（边缘专家）：8分
专家B（颜色专家）：6分
专家C（纹理专家）：9分
...
专家Z（其他专家）：5分
```

我们要综合这些意见，形成64个决策要点：

1. 决策要点1（例如"是否是动物"）：

```
权重：边缘专家×0.3 + 颜色专家×0.2 + 纹理专家×0.4 + ...
计算：8×0.3 + 6×0.2 + 9×0.4 + ... = 7.2分
结果：7.2分表示"很可能是动物"
```

2. 决策要点2（例如"是否在运动"）：

```
不同的权重组合...
```

这样，256个详细意见 → 64个综合决策要点

### 对比全连接

| 特性       | 1×1卷积                                      | 全连接层                                  |
|------------|---------------------------------------------|------------------------------------------|
| 输入形状   | [C, H, W]（保持空间结构）                   | 必须展平为向量（例如 C×H×W）             |
| 输出形状   | [C', H, W]（保持空间结构不变）              | 向量（长度 C'）                           |
| 空间信息   | 保留（每个位置独立处理）                    | 丢失（混合所有位置信息）                   |
| 参数量     | C×C'（相对较少）                            | C×H×W × C'（通常非常巨大）                |
| 用途       | 特征图通道变换、跨通道交互、降维/升维       | 最终分类、特征整合                        |

### 在ResNet50 bottleneck中的具体应用

```cpp
// ResNet50的bottleneck结构
输入：[256, H, W]
    ↓
1×1卷积：降维到[64, H, W]  ← 降维
    ↓
3×3卷积：[64, H, W] → [64, H, W]（可能stride=2降采样）
    ↓  
1×1卷积：升维到[256, H, W] ← 升维
    ↓
残差连接：输入+输出
```

***为什么这样设计？***

1. **先降维**：减少3×3卷积的计算量（从256×256→64×64，计算量减少16倍）
2. **中间处理**：用较小的通道数做主要处理
3. **再升维**：恢复通道数，与输入残差连接

假设我们有一张3×3的简单猫图片（为了演示简化）

```
原图（3×3，RGB）：
像素坐标     R    G    B
(0,0)     100  50   20   ← 猫耳朵（橙色）
(0,1)     120  70   30   ← 猫耳朵
(0,2)     80   40   10   ← 背景
(1,0)     90   60   25   ← 猫脸
(1,1)     110  80   40   ← 猫眼睛（中心）
(1,2)     70   30   5    ← 背景
(2,0)     85   55   22   ← 猫下巴
(2,1)     95   65   28   ← 猫脖子
(2,2)     60   20   0    ← 背景
```

# CNN骨干

## 第1步：图片输入

***注意：此时输入张量为`[批次, 通道, 高, 宽] = [1, 3, 3, 3]`***

```python
# 输入张量形状：[批次, 通道, 高, 宽] = [1, 3, 3, 3]
input_image = torch.tensor([[
    [[[100, 120, 80],    # 第0行，RGB通道
       [90, 110, 70],    
       [85, 95, 60]]],   # R通道（红色）
     
    [[[50, 70, 40],      # G通道（绿色）
       [60, 80, 30],
       [55, 65, 20]]],
     
    [[[20, 30, 10],      # B通道（蓝色）
       [25, 40, 5],
       [22, 28, 0]]]
]])
```
> **此时**：计算机看到的是原始像素值（0-255），没有"猫"的概念。

## 第2步：第一层卷积（提取边缘/纹理）

假设第一层有4个卷积核（4种"检测器"）：

```cpp
// 卷积核1：检测"左上到右下的边缘"
kernel1 = [[ 1,  0, -1],
           [ 0,  0,  0],
           [-1,  0,  1]]

// 卷积核2：检测"垂直边缘"
kernel2 = [[-1,  0,  1],
           [-1,  0,  1],
           [-1,  0,  1]]

// 卷积核3：检测"水平边缘"
kernel3 = [[-1, -1, -1],
           [ 0,  0,  0],
           [ 1,  1,  1]]

// 卷积核4：检测"角点"
kernel4 = [[ 1, -1, -1],
           [-1,  1, -1],
           [-1, -1,  1]]
```

**计算过程**（以R通道 + kernel1为例）：

```
R通道的3×3区域（以(1,1)为中心）：
[100, 120, 80]
[90, 110, 70]
[85, 95, 60]

卷积计算：
100×1 + 120×0 + 80×(-1) +
90×0 + 110×0 + 70×0 +
85×(-1) + 95×0 + 60×1
= 100 - 80 - 85 + 60 = -5
```
> 由此可得一个[3, 3]的矩阵

对每个位置、每个通道、每个卷积核都计算：

***注意：此时第一个特征图为`[批次, 通道（对应4个卷积核）, 高, 宽] = [1, 4, 3, 3]`***

```python
# 第一个特征图（简化值）：
feature_map1_channel1 = [[-5, 10, 15],   # kernel1的输出
                         [8, -5, 12],
                         [7, 9, -3]]
                         
feature_map1_channel2 = [[-8, 5, 12],    # kernel2的输出
                         [6, -8, 10],
                         [5, 7, -5]]
                         
feature_map1_channel3 = [[-3, 8, 10],    # kernel3的输出
                         [7, -3, 9],
                         [6, 8, -2]]

feature_map1_channel4 = [[-2, 6, 8],     # kernel4的输出
                         [5, -2, 7],
                         [4, 6, -1]]
```
> **此时**：我们得到了4个特征图，每个检测不同的边缘/纹理模式。

## 第3步：激活函数(ReLU)

```python
# ReLU：把所有负数变成0，正数保持不变

feature_map1_channel1_after_relu = [[0, 10, 15],   # -5变成0
                                    [8, 0, 12],
                                    [7, 9, 0]]
```
> *为什么？*因为负值通常表示"**没有这个特征**"
> **直觉**：只保留"有这种特征"的位置，去掉"没有这种特征"的位置。

## 第4步：池化（下采样）

假设用2×2最大池化，步长2：

```python
# 对feature_map1_channel1_after_relu：
[[0, 10, 15],
 [8, 0, 12],
 [7, 9, 0]]

# 分成2×2的区域，取最大值：
# 区域1: [[0,10], [8,0]] → 最大值=10
# 区域2: [[15], [12]] → 最大值=15
# 区域3: [[7,9]] → 最大值=9
# 区域4: [[0]] → 最大值=0

# 输出：[1, 4, 2, 2]  ← 尺寸从3×3变成2×2
pooled_feature_map1_channel1 = [[10, 15],
                                [9, 0]]
```
> 减少计算量（特征图变小）
> 增加感受野（每个像素看到更大区域）
> 增加平移不变性（物体移动一点，特征还在）

## 第5步：多层卷积堆叠

现在我们有4个2×2的特征图。再通过第二层卷积：

```python
# 每个卷积核要看第一层的所有4个通道！
# 这样能组合第一层的简单特征，形成复杂特征

kernel5 = [[[0.1, 0.2, 0.3],   # 看channel1的权重
            [0.4, 0.5, 0.6],
            [0.7, 0.8, 0.9]],
           
           [[-0.1,-0.2,-0.3],  # 看channel2的权重
            [-0.4,-0.5,-0.6],
            [-0.7,-0.8,-0.9]],
           
           [[0.2, 0.1, 0.3],   # 看channel3的权重
            [0.5, 0.4, 0.6],
            [0.8, 0.7, 0.9]],
           
           [[-0.2,-0.1,-0.3],  # 看channel4的权重
            [-0.5,-0.4,-0.6],
            [-0.8,-0.7,-0.9]]]
```

**计算**：在位置(0,0)，卷积核5要看：
- 第一层4个特征图的(0,0)为中心的3×3区域
- 由于padding，实际可能看补0后的区域
**直觉**：第二层卷积核能检测"边缘的组合"，比如：
- 卷积核5：检测"两个垂直边缘中间有个角点"（可能是猫眼睛）
- 卷积核6：检测"水平边缘上有纹理"（可能是猫毛皮）

## 第6步：残差连接（ResNet的关键）

```python
# 假设输入是X，卷积输出是F(X)
# 残差连接：输出 = F(X) + X

# 为什么？防止梯度消失，让深层网络能训练
```

