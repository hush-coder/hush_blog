***compiler-basic 语法分析-1***

# 目录

# 目标

负责将词法分析产生的令牌（Token）序列，按照给定的文法规则（Grammar）组织成语法结构，通常是一棵抽象语法树（Abstract Syntax Tree, AST）。

***注意：这里不在乎语义结构***

# 上下文无关文法（CFG）

## 终结符和非终结符

特性 | 终结符 | 非终结符 
| :--- | :--- | :--- |
来源 | 直接从源代码中由词法分析器提取 | 由编译器设计者发明，用于描述语法结构 
实质 | 编程语言的"单词" | 语法结构的"类别名称" |
在树中位置 | 叶子节点 | 内部节点
例子 | `if, while, +, (, x, 42` | `<statement>, <expression>, <if_statement>`

- 终结符是你在源代码里能直接看到的。
- 非终结符是你在编译器的文法规则里看到的，它们用来给令牌序列赋予结构意义。

## 产生式规则与产生式

终结符 (Tokens): `id（标识符）`， `number（数字）`， `=`, `+`, `-`, `*`, `/`, `;`

非终结符 (语法结构): `<program>`, `<statement>`, `<assignment>`, `<expression>`, `<term>`, `<factor>`

### 产生式规则

那么可以定义产生式规则如下：

```
<program>      -> <statement> <program> | ε

<statement>    -> <assignment> ;

<assignment>   -> id = <expression>

<expression>   -> <expression> + <term> | <expression> - <term> | <term>

<term>         -> <term> * <factor> | <term> / <factor> | <factor>

<factor>       -> id | number | ( <expression> )
```

### 产生式

概念 | 定义 | 例子
| :--- | :--- | :--- |
产生式 | 单个替换规则 | `E → E + T`
产生式规则 | 一组相关的产生式 | `E → E + T | E - T | T`

```
产生式规则1:
<expression> → <expression> + <term>
             | <expression> - <term>
             | <term>

产生式规则2:  
<term> → <term> * <factor>
        | <term> / <factor>
        | <factor>

产生式规则3:
<factor> → ( <expression> )
          | number
          | identifier
```

***这里包含了9个产生式，分为3个产生式规则。***



# 自顶向下分析法

从文法的开始符号出发，尝试推导出整个输入字符串。从树根开始，尝试生长出与输入令牌流完全匹配的枝叶。

1. 从开始符号出发
2. 反复用产生式的右部替换左部的非终结符
3. 最终得到一个与输入令牌序列完全匹配的终结符序列

**挑战：**

- 当面临多个产生式选择时，如何确定使用哪一个？
- 如何避免无限循环？

## 递归下降分析法

**一个非终结符 = 一个解析函数**

### 解析函数

每个解析函数负责：

1. 识别并验证属于该非终结符的结构

2. 调用其他解析函数来处理子结构

3. 构建相应的AST节点

### 使用预测集

每个函数通过查看下一个输入令牌（向前看符号）来决定使用哪条产生式。

```python
# 伪代码示例：解析if语句
def parse_if_statement():
    match(IF)  # 消费'if'令牌
    match(LEFT_PAREN)  # 消费'('
    condition = parse_expression()  # 递归解析条件表达式
    match(RIGHT_PAREN)  # 消费')'
    then_branch = parse_statement()  # 解析then分支
    
    # 查看下一个令牌决定是否有else分支
    if current_token == ELSE:
        match(ELSE)
        else_branch = parse_statement()
        return IfStatement(condition, then_branch, else_branch)
    else:
        return IfStatement(condition, then_branch, None)
```

### 令牌匹配（match函数）

- `match(token_type)`：检查当前令牌是否与期望类型匹配，如果匹配则消费该令牌并前进到下一个令牌
- 如果不匹配，报告语法错误

### 错误处理

递归下降分析器可以实现精细的错误恢复策略：
- **恐慌模式恢复**：跳过输入直到找到同步令牌
- **短语级恢复**：在错误位置插入/删除/修改令牌

### 局限性

- **需要处理左递归**：直接左递归会导致无限递归
- **可能需要回溯**：如果不是LL(1)文法，可能需要尝试多条路径

## LL（1）分析法

- **L**：从左到右扫描输入
- **L**：产生最左推导
- **(1)**：只需向前看1个输入符号

### 预测分析表

一个二维表格，指导分析过程：

- **行**：非终结符
- **列**：终结符（包括$）
- **单元格**：应该应用的产生式规则

#### FIRST(α)

能从符号串α推导出的所有开头终结符的集合

*计算规则*：

- 如果X是终结符，FIRST(X) = {X}

- 如果X是非终结符，对于每个产生式X → Y₁Y₂...Yₖ：

    1. 把FIRST(Y₁)中除ε外的所有符号加入FIRST(X)
    2. 如果ε ∈ FIRST(Y₁)，再把FIRST(Y₂)中除ε外的所有符号加入FIRST(X)
    3. 依此类推，如果所有Yᵢ都能推导出ε，则ε ∈ FIRST(X)

#### FOLLOW(A)

在某些句型中，能紧跟在非终结符A后面的终结符的集合

*计算规则：*

- 对于开始符号S，把$加入FOLLOW(S)
- 如果有产生式A → αBβ，把FIRST(β)中除ε外的所有符号加入FOLLOW(B)
- 如果有产生式A → αB，或A → αBβ且ε ∈ FIRST(β)，把FOLLOW(A)加入FOLLOW(B)

#### 建表算法

对于每个产生式A → α：

1. 对每个终结符a ∈ FIRST(α)，将A → α加入M[A, a]
2. 如果ε ∈ FIRST(α)，对每个终结符b ∈ FOLLOW(A)，将A → α加入M[A, b]

### 条件

当且仅当它的预测分析表中每个单元格最多只有一个产生式。

这意味着：

1. 文法无左递归
2. 对于每个非终结符A和它的任意两个不同产生式A→α和A→β，满足：
    - FIRST(α) ∩ FIRST(β) = ∅
    - 如果ε ∈ FIRST(α)，那么FIRST(β) ∩ FOLLOW(A) = ∅

***意思就是每个非终结符想要得到某个终结符，必须只有一条路径***

#### 处理左递归

原始文法（左递归）：

```
expression → expression + term
           | expression - term  
           | term
```

转换后（右递归）：

```
expression → term expression'
expression' → + term expression'
            | - term expression'
            | ε  # 空产生式
```

#### 处理公共左因子

当多个产生式有相同前缀时，需要提取左公因子：

**原始文法:**

```
statement → if ( expression ) statement
          | if ( expression ) statement else statement
```

**转换后：**

```
statement → if ( expression ) statement else_clause
else_clause → else statement | ε
```

### 如何工作

两个空间：分析栈、输入缓冲区

分析栈内根据查表不断替换，目的是凑出当前输入（目标语句中的终结符）。凑出来之后更新输入，重新凑。

### 与递归下降对比

LL（1）就是自动化的递归下降

递归下降的函数调用栈 ≈ LL(1)的显式分析栈。

**递归下降的应用方式：**

```python
# 应用产生式 E -> T E'
def parse_expression():
    parse_term()      # 对应 T
    parse_expression_prime()  # 对应 E'
```

**LL(1)的应用方式：**

```python
# 应用相同的产生式 E -> T E'
stack.pop()  # 弹出E
stack.append('E\'')  # 先压E'
stack.append('T')    # 再压T
```

让我们分析输入 id + id，观察两种方法如何执行相同的步骤：

递归下降的执行轨迹：

```
1. parse_expression()        [输入: id + id $]
   → 看到'id'，选择 E -> T E'
   
2.   parse_term()            [输入: id + id $]  
     → 看到'id'，选择 T -> F T'
     (这里用的是传统的if-else)
     
3.     parse_factor()        [输入: id + id $]
       → 看到'id'，选择 F -> id
       → 匹配'id'，消费输入
       
4.     parse_term_prime()    [输入: + id $]
       → 看到'+'，选择 T' -> ε
       
5.   parse_expression_prime()[输入: + id $]
     → 看到'+'，选择 E' -> + T E'
     → 匹配'+'，消费输入
     
6.     parse_term()          [输入: id $]
       → 看到'id'，选择 T -> F T'
       
7.       parse_factor()      [输入: id $]
         → 看到'id'，选择 F -> id  
         → 匹配'id'，消费输入
         
8.       parse_term_prime()  [输入: $]
         → 看到'$'，选择 T' -> ε
         
9.     parse_expression_prime()[输入: $]
       → 看到'$'，选择 E' -> ε
```

LL(1)的等效执行轨迹：

```
栈          输入          动作
E $         id + id $     E -> T E'
T E' $      id + id $     T -> F T'  
F T' E' $   id + id $     F -> id
id T' E' $  id + id $     匹配id
T' E' $     + id $        T' -> ε
E' $        + id $        E' -> + T E'
+ T E' $    + id $        匹配+
T E' $      id $          T -> F T'
F T' E' $   id $          F -> id  
id T' E' $  id $          匹配id
T' E' $     $             T' -> ε
E' $        $             E' -> ε
$           $             接受
```

## LL(k)分析法

往前看多个token

### 为什么需要

```
语句 -> 标识符 ( 参数列表 )   # 函数调用
      | 标识符 [ 表达式 ]     # 数组访问
```

*在LL(1)中：*

- FIRST(函数调用) = {标识符}
- FIRST(数组访问) = {标识符}

**冲突！ 看到标识符后不知道选择哪条规则**

*在LL(2)中：*

看到标识符后，再向前看第二个符号：

- 如果是( → 选择函数调用
- 如果是[ → 选择数组访问

### 预测机制

LL(1)的预测表：

```
非终结符 × 1个符号 → 产生式
```

LL(k)的预测表：

```
非终结符 × k个符号序列 → 产生式
```

具体实现：

```python
# LL(1)的预测表（简单）
ll1_table = {
    'E': {
        'id': "T E'",
        '(': "T E'"
    },
    'E\'': {
        '+': "+ T E'",
        ')': "ε",
        '$': "ε"
    }
}

# LL(k)的预测表（更强大）
llk_table = {
    'statement': {
        # 看到 "id (" 选择函数调用
        ('id', '('): "id ( param_list )",
        # 看到 "id [" 选择数组访问  
        ('id', '['): "id [ expression ]",
        # 看到 "if (" 选择if语句
        ('if', '('): "if ( expression ) statement",
        # 看到多个关键字的组合
        ('while', '('): "while ( expression ) statement",
        ('for', '('): "for ( init ; condition ; update ) statement"
    }
}
```

### FIRST_k 和 FOLLOW_k

**FIRST_k(α)**
- **定义**：从符号串α可以推导出的所有前k个符号的集合
- **计算**：考虑所有可能的推导，收集每个推导结果的前k个符号

**FOLLOW_k(A)**
- **定义**：在某些句型中，紧跟在非终结符A后面的k个符号的集合

### 问题

- 预测表爆炸（压缩数据结构或切换到LL(*)）
- 仍然无法处理左递归
- k值选择（平衡精确性和性能）

## LL（*）分析法

传统的LL(k)需要预先确定向前看k个符号，而LL(*)能够动态决定需要向前看多远，直到能够唯一确定语法规则。

### NFA（非确定性有限自动机）

- 从文法规则自然构建状态机
- 允许不确定性：一个状态可以有多个转移
- 同时跟踪所有可能的分析路径

```
# NFA状态转移示例
NFA = {
    'S0': {'a': ['S1', 'S2']},  # 不确定性：看到a可到S1或S2
    'S1': {'b': ['S3']},
    'S2': {'c': ['S4']}
}
```

*特点：*

1. 多状态同时活跃：像多个侦探同时调查所有线索
2. 并行探索：不立即做决定，保持所有可能性开放
3. 自然建模：直接反映文法规则的不确定性

### DFA（确定性有限自动机）

- 将NFA确定化，提高运行时效率
- 提供快速的状态转移决策
- 处理90%的常规语法情况

*特点：*

1. O(1)决策速度：直接查表，无需回溯
2. 确定性：每个输入都产生唯一确定的转移
3. 高效执行：适合处理大多数常规语法模式

### NFA -> DFA

1. **子集构造法**：将NFA的状态组映射为DFA的单个状态
2. **消除不确定性**：每个DFA状态代表NFA中可能同时活跃的一组状态
3. **构建转移表**：创建高效的查表机制

### 语法谓词

- 处理DFA无法解决的复杂歧义
- 提供上下文相关的决策能力
- 突破有限状态自动机的理论限制

*分类：*

1. 语法谓词：`( ... )=>` - 检查语法模式
2. 语义谓词：`{ ... }?` - 检查语义条件
3. 门控谓词：基于外部状态的决策

*工作机制：*

```
def 语法谓词(输入流):
    保存当前分析状态()      # 备份位置、栈等
    尝试:
        执行试解析()        # 尝试解析特定语法结构
        返回 成功?True:False
    最后:
        恢复分析状态()      # 无论结果如何都恢复状态
```

### 工作流程

1. 文法规则分析(这里需要标记需要特殊处理的复杂情况和识别可能的歧义点)
2. 构建向前看NFA
3. NFA确定化为DFA
4. 语法谓词配置
5. DFA优先处理
6. DFA决策过程
7. 语法谓词决策过程

```
def 解析非终结符(非终结符, 输入流):
    # 首先尝试DFA快速决策
    dfa = 获取DFA(非终结符)
    产生式 = dfa.预测(输入流)
    
    if 产生式 is not None:
        return 应用产生式(产生式)  # DFA成功，直接返回
    else:
        return 触发语法谓词(非终结符, 输入流)  # DFA失败，使用谓词
```
