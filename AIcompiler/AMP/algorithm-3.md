***AMP-algorithm篇（3）代理模型-1***

# 摘要

本文介绍了代理模型在AI编译器混精优化中的应用，分析了六种主流代理模型的特点、优缺点和适用场景，为混精优化项目选择合适的代理模型提供参考。

# 目录

- [摘要](#摘要)
- [目录](#目录)
- [前言](#前言)
- [什么是代理模型？](#什么是代理模型)
  - [特点](#特点)
  - [混精中的应用](#混精中的应用)
- [几种选择](#几种选择)
  - [随机森林回归 ⭐⭐⭐⭐⭐](#随机森林回归-)
    - [优缺点](#优缺点)
      - [优点](#优点)
      - [缺点](#缺点)
    - [具体流程](#具体流程)
      - [1. Bootstrap采样](#1-bootstrap采样)
      - [2. 特征和分裂点选择](#2-特征和分裂点选择)
      - [3. 构建决策树](#3-构建决策树)
      - [4. 集成预测](#4-集成预测)
    - [In My Project](#in-my-project)
      - [特征选取](#特征选取)
  - [高斯过程回归 ⭐⭐⭐⭐⭐](#高斯过程回归-)
    - [优缺点](#优缺点-1)
      - [优点](#优点-1)
      - [缺点](#缺点-1)
    - [具体流程](#具体流程-1)
      - [1. 模型初始化](#1-模型初始化)
      - [2. 训练过程](#2-训练过程)
      - [3. 预测与不确定性](#3-预测与不确定性)
  - [多任务贝叶斯优化 ⭐⭐⭐⭐](#多任务贝叶斯优化-)
    - [优缺点](#优缺点-2)
      - [优点](#优点-2)
      - [缺点](#缺点-2)
    - [具体流程](#具体流程-2)
      - [1. 多任务模型构建](#1-多任务模型构建)
      - [2. 采集函数优化](#2-采集函数优化)
      - [3. 多目标权衡](#3-多目标权衡)
      - [4. 迭代优化](#4-迭代优化)
    - [适用场景](#适用场景)
  - [梯度提升树特征工程 ⭐⭐⭐⭐](#梯度提升树特征工程-)
    - [优缺点](#优缺点-3)
      - [优点](#优点-3)
      - [缺点](#缺点-3)
    - [具体流程](#具体流程-3)
      - [1. 基础模型训练](#1-基础模型训练)
      - [2. 特征交互提取](#2-特征交互提取)
      - [3. 新特征构建](#3-新特征构建)
      - [4. 特征重要性排序](#4-特征重要性排序)
    - [适用场景](#适用场景-1)
  - [元学习初始化 ⭐⭐⭐](#元学习初始化-)
    - [优缺点](#优缺点-4)
      - [优点](#优点-4)
      - [缺点](#缺点-4)
    - [具体流程](#具体流程-4)
      - [1. 元知识提取](#1-元知识提取)
      - [2. 快速适应](#2-快速适应)
      - [3. 知识迁移](#3-知识迁移)
      - [4. 持续更新](#4-持续更新)
    - [适用场景](#适用场景-2)
  - [图神经网络（GNN）⭐⭐](#图神经网络gnn)
    - [优缺点](#优缺点-5)
      - [优点](#优点-5)
      - [缺点](#缺点-5)
    - [具体流程](#具体流程-5)
      - [1. 图结构构建](#1-图结构构建)
      - [2. 图神经网络设计](#2-图神经网络设计)
      - [3. 表示学习](#3-表示学习)
      - [4. 性能预测](#4-性能预测)
    - [适用场景](#适用场景-3)
  - [核心路线](#核心路线)
- [总结](#总结)

# 前言

本人正在搞AI编译器，这个博客大家可以当作学习笔记。

# 什么是代理模型？

代理模型，也称为替代模型或元模型，是一种用于近似复杂、计算昂贵的函数或系统的简化模型。

## 特点

- **计算效率高**：相比原始函数，代理模型的计算成本极低
- **近似精度**：在给定区域内能够较好地近似原始函数
- **可微性**：通常具有良好的数学性质，便于优化算法使用

## 混精中的应用

评测程序消耗过大，会严重影响模型**收敛速度**，通过建立代理模型可以**快速预估**当前配置的分数，来避免部分额外的不必要的测试。

***缓存配置是为了让已测配置不再测，代理模型是为了未测配置不需测，都是为了提高收敛速度***

# 几种选择

## 随机森林回归 ⭐⭐⭐⭐⭐

### 优缺点

#### 优点

- **离散特征处理**：完美处理精度类型（double/float/half）选择
- **鲁棒性强**：对异常值、噪声不敏感
- **特征重要性**：清晰显示哪些配置参数影响最大
- **训练简单**：不需要复杂的超参数调优
- **可解释性**：容易理解模型决策过程
- **处理缺失值**：对数据质量要求不高

#### 缺点

- **预测精度**：相比深度学习模型可能略低
- **连续值处理**：对连续参数空间不如GP模型
- **内存占用**：树模型可能占用较多内存

### 具体流程

#### 1. Bootstrap采样

从一系列训练集中有从训练集中**有放回**地随机抽取样本，构建多个子数据集
> 每个子数据集构建一个决策树。

#### 2. 特征和分裂点选择

评估每个特征和分裂点的**基尼系数**，选出最纯净并且最均匀的那个
> 此处最纯净指的是同一组内差距不大

#### 3. 构建决策树

根据选出的各个子数据集的最佳特征和分裂点配置，构建该数据集的**决策树**。各个决策树合起来成为**随机森林**。
> 避免偏听则信

#### 4. 集成预测

所有树的预测结果取平均值。

### In My Project

#### 特征选取

可以使用double比例、float比例、half比例等作为特征。

## 高斯过程回归 ⭐⭐⭐⭐⭐

### 优缺点

#### 优点

- **不确定性量化**：提供预测置信区间，对优化算法极有价值
- **样本效率高**：在有限评估次数下表现优异
- **连续优化友好**：适合遗传算法的参数空间
- **核函数灵活**：可以适应不同的数据分布
- **贝叶斯框架**：理论基础扎实

#### 缺点

- **计算复杂度**：$O(n³)$的复杂度，样本量大时计算昂贵
- **核函数选择**：需要选择合适的核函数
- **离散特征处理**：对分类特征需要特殊处理

### 具体流程

#### 1. 模型初始化

用一定量的配置来初始化模型，选择合适的核函数
> 核函数就是计算相似度的函数
>
> 数据集需符合**高斯分布**，即不存在严重不合理的数据，这一点我们的数据集可以做到

#### 2. 训练过程

根据已有数据进行训练

#### 3. 预测与不确定性

获取其不确定性。

## 多任务贝叶斯优化 ⭐⭐⭐⭐

**适合多目标优化**

### 优缺点

#### 优点
- **多目标处理**：同时优化性能和精度
- **样本效率**：在有限评估次数下表现优异
- **全局优化**：避免陷入局部最优
- **采集函数**：智能选择下一个评估点

#### 缺点
- **实现复杂**：需要设计多任务模型
- **计算开销**：每次建议都需要优化采集函数
- **超参数敏感**：对模型参数设置敏感

### 具体流程

#### 1. 多任务模型构建
构建能够同时处理多个目标（性能、精度、编译时间）的代理模型
> 每个任务都有自己的代理模型，但共享底层表示

#### 2. 采集函数优化
设计智能的采集函数，平衡探索（高不确定性）和利用（高预测值）
> 采集函数决定下一个应该测试的配置点

#### 3. 多目标权衡
使用帕累托前沿或加权方法处理多个目标之间的冲突
> 找到性能、精度、编译时间的最优平衡点

#### 4. 迭代优化
基于采集函数的建议选择新配置，更新代理模型，重复优化过程

### 适用场景
如果需要同时优化多个目标（性能、精度、编译时间）。

## 梯度提升树特征工程 ⭐⭐⭐⭐

**适合特征提取和重要性分析**

### 优缺点

#### 优点
- **特征工程**：自动发现特征间的交互关系
- **非线性建模**：捕捉复杂的配置-性能关系
- **特征重要性**：提供详细的特征分析
- **预测精度**：通常比随机森林精度更高

#### 缺点
- **过拟合风险**：容易在训练集上过拟合
- **训练时间**：比随机森林训练时间长
- **参数敏感**：需要仔细调优超参数

### 具体流程

#### 1. 基础模型训练
训练一个梯度提升树模型作为基础预测器
> 使用配置参数作为特征，性能分数作为目标

#### 2. 特征交互提取
分析树模型的分裂点，提取特征间的交互关系
> 发现哪些配置参数组合对性能影响最大

#### 3. 新特征构建
基于提取的交互关系，构建新的复合特征
> 例如：double_ratio × float_ratio、精度比例的组合等

#### 4. 特征重要性排序
计算每个特征（包括新构建的）的重要性分数
> 为后续的代理模型提供更好的特征输入

### 适用场景
作为特征工程工具，为其他模型提供更好的特征输入。

## 元学习初始化 ⭐⭐⭐

**适合知识迁移**

### 优缺点

#### 优点
- **快速适应**：从历史经验中快速学习
- **减少冷启动**：避免从随机配置开始
- **知识迁移**：在不同精度配置间迁移学习
- **持续改进**：随着经验积累不断改进

#### 缺点
- **实现复杂**：需要设计元学习算法
- **历史数据依赖**：需要大量历史优化数据
- **迁移效果**：不同任务间的迁移效果不确定

### 具体流程

#### 1. 元知识提取
从历史优化数据中提取通用的配置-性能模式
> 学习"什么样的配置通常表现更好"的元知识

#### 2. 快速适应
新任务开始时，基于元知识快速初始化代理模型
> 避免从零开始学习，利用历史经验

#### 3. 知识迁移
将学到的模式迁移到新的精度配置或编译目标
> 在不同但相关的任务间共享知识

#### 4. 持续更新
随着新数据的积累，不断更新元知识库
> 元知识会随着经验增长而改进

### 适用场景
如果有丰富的历史优化数据，且需要快速适应新任务。

## 图神经网络（GNN）⭐⭐

**相对复杂，收益有限**

### 优缺点

#### 优点
- **结构建模**：可以建模配置间的依赖关系
- **表示学习**：学习配置的向量表示
- **端到端**：可以端到端地学习配置-性能映射

#### 缺点
- **实现复杂**：需要设计图结构和GNN架构
- **数据要求**：需要大量的图结构数据
- **计算开销**：训练和推理都比较昂贵
- **收益有限**：在混精优化项目中可能收益不如其他模型

### 具体流程

#### 1. 图结构构建
将混精配置构建为图结构，节点表示配置参数，边表示参数间的关系
> 需要定义配置参数之间的连接关系

#### 2. 图神经网络设计
设计适合配置优化的GNN架构（如GCN、GAT等）
> 选择合适的消息传递和聚合机制

#### 3. 表示学习
通过图神经网络学习配置的向量表示
> 捕捉配置参数间的复杂依赖关系

#### 4. 性能预测
基于学习到的配置表示，预测性能分数
> 端到端地学习配置到性能的映射

### 适用场景
如果配置空间有明确的图结构关系。

## 核心路线

**立即实施：** 随机森林回归 + 高斯过程回归
**中期考虑：** 梯度提升树特征工程优化随机森林

# 总结

代理模型是混精优化中提高效率的关键技术。通过合理选择和组合不同的代理模型，可以显著提升优化算法的性能，减少不必要的计算开销。建议从随机森林和高斯过程回归开始，逐步扩展到更高级的模型，确保在获得收益的同时控制实现复杂度。

***缓存配置是为了让已测配置不再测，代理模型是为了未测配置不需测，都是为了提高收敛速度***