# deepseek

# 问题一

## 问题

刚才我们讨论了SSA和Phi节点，理解得不错。现在我们继续第一轮。问题2：LLVM的Pass管理器中，有ModulePass、FunctionPass和BasicBlockPass等类型。请解释它们的区别，并分别举例说明它们各自适合做什么类型的优化。

## 我的回答

首先这三者都是pass的类型，在全链路中处于中端的位置，对于初始生成的LLVMIR进行优化。三者对应了LLVM中的三个不同的层次结构：Module、function、BB块，从左到右嵌套。对于ModulePass呢，更多的是在Module层对于IR做一些标准化格式化方面的优化、对于function pass可以做一些类似于常量折叠、死代码消除之类的代码层面的优化，对于BasicBlockPass，可以做一些BB块调度层面和SSA上的优化

## Deepseek点评

### 优点

- 你正确地识别了三种Pass对应不同层次结构
- 你知道它们嵌套关系：Module > Function > BasicBlock

### 缺点

***关于ModulePass：***

不准确：你提到“标准化格式化方面的优化”，这更像是前端工作。ModulePass的核心价值是跨函数优化。

正确理解：ModulePass能访问整个模块的所有信息，适合做：
- 函数内联（Inlining）：需要知道调用关系
- 全局值编号（GVN）：需要跨函数识别相同值
- 全局死代码消除：需要整个模块的引用信息
- 链接时优化（LTO）：整合多个编译单元

***关于FunctionPass：***

你的例子基本正确，但可以更具体：
- 常量折叠、死代码消除确实是FunctionPass的典型应用
- 但最好说明为什么：因为它们在单个函数内就能完成

***关于BasicBlockPass：***

- 重要事实：BasicBlockPass在现代LLVM中已被废弃
- 原因：限制太多，优化效果有限，且影响Pass管理器效率
- 你提到的“SSA上的优化”不太准确：SSA相关优化通常在FunctionPass层面

***缺少的关键点***

- 没有提到Pass执行顺序和依赖关系
- 没有提到新的PassManager架构（现在主流）
- 没有提到LoopPass（非常重要，专门处理循环优化）

### better anwser

“LLVM的Pass管理器中有不同粒度的Pass，对应不同的优化范围：

1. ModulePass：处理整个LLVM模块（包含多个函数和全局变量）。它能访问模块的所有信息，适合进行跨函数优化，比如：
- 函数内联：需要知道调用图
- 全局值编号（GVN）：识别整个模块中相同的计算
- 链接时优化：整合多个编译单元的信息

2. FunctionPass：处理单个函数，不能保持跨函数的状态（除非通过Pass管理器重新调度）。适合函数内局部优化，比如：
- 指令简化：常量折叠、代数化简
- 死代码消除：删除无用的指令
- 循环不变代码外提：需要分析循环结构

3. BasicBlockPass（已废弃）：原本设计用于单个基本块的优化，但因为限制太多，在现代LLVM中已经被废弃。现在LLVM鼓励使用FunctionPass，即使在基本块层面操作。

**补充说明：**

- 现代LLVM的新PassManager还有LoopPass（专门优化循环）、CGSCCPass（基于调用图强连通分量）等
- Pass之间有依赖关系，比如某些优化需要先进行别名分析
- Pass管理器会确保依赖的Pass先执行”

# 问题二

## 问题

你知道LLVM中的别名分析（Alias Analysis）吗？为什么它在编译器优化中很重要？举一个依赖别名分析的优化例子。

# 问题三

## 问题

“我理解。那我们从最基础的开始。你现在在理想汽车做NPU算子优化，肯定经常遇到性能问题。告诉我，当你发现一个算子跑得慢时，你的第一反应是什么？具体会怎么做？”

## 回答

对于单个算子的性能异常，其实我们首先并不会从单个算子来看，而是会追溯到整个模型的网络。对于优化思路，我们来分情况讨论一下：
如果这个算子是我们的编译栈生成的话，相比于改进编译栈，其实更直接的方式是直接把相应的subnet扣出来手写。
如果算子已经是手写。我们会判断他是计算密集型算子还是访存密集型算子，再用性能分析工具来定位一下性能瓶颈。如果在访存上出现了瓶颈，我们会考虑到或许是内存从TM上面溢出了？或许是访存过于密集？前者我们会加强数据流水，在特定的轴上面切分，确保单次流水不会溢出内存（这里可以用一些内存复用的策略）；后者我们可能会在计算图层面上考虑算子融合来减少DDR的数据读取。如果是计算上出现了瓶颈，我们会查看tile利用率，或许是并行度设计不够，亦或者是同步方面出现了问题，针对此我们或许会采用更小粒度的的同步方式。
针对计算瓶颈，我们可能会去采用循环优化，例如转置换轴，SIMD计算等等

## Deepseek的点评

非常好。这个回答展现了你扎实的工程实践思维和清晰的优化方法论，远超一般本科生的水平。

**我注意到的几个亮点：**

1. 系统性视角：你没有孤立地看算子，而是先追溯到模型网络层面。这是高级工程师的思维习惯。
2. 问题拆解能力：你清晰地分为了“编译生成”和“手写”两种情况，并抓住了“计算密集”与“访存密集”这个最根本的性能 dichotomy。
3. 技术词汇准确：你提到了“tile利用率”、“算子融合”、“数据流水”、“内存复用”等核心概念，说明你不是纸上谈兵。
4. 解决方案具体：针对访存瓶颈，你提到了“加强数据流水”、“特定轴切分”、“算子融合”；针对计算瓶颈，提到了“循环优化”、“转置换轴”、“SIMD”。这些都是业界标准且有效的优化手段。

**可以进一步提升的地方（让回答更出彩）：**

- 具体化工具和指标：提到“性能分析工具”时，如果能说出具体名字（如针对NPU的nsys、nlprof，或通用CPU/GPU的perf、nsight-compute）并说明你关注的关键指标（如计算单元利用率、缓存命中率、带宽占用），会显得更专业。
- 给出一个具体案例：在概述方法论后，如果能补充一句：“比如我最近优化的一个DepthwiseConv算子，通过nlprof发现是L1带宽瓶颈，然后我们采用了将Kh和Kw循环展开并与C轴进行tiling的策略，最终在XXX硬件上获得了XX%的性能提升。”这样的回答会极具说服力。

解释“为什么”：可以简短解释一下为什么“算子融合”能减少DDR读取。这说明你理解背后的原理，而不只是知道技术名词。

# 问题四

## 问题

“你刚才的回答思路非常清晰。现在，我们聚焦到一个具体的场景，这也是我考察所有候选人实际经验的关键问题。”

“请描述一个你亲身经历、印象最深刻的算子性能优化案例。请使用STAR法则来回答：当时是什么情境（S），你要完成什么任务（T），你具体采取了哪些行动（A），最终得到了什么结果（R）？”

## 回答

我最近优化的一个算子是Deformable DETR中的msda。但是我接到了我的mentor给我的任务，就是去优化msda的性能，从9ms优化到2ms。我接到了之后其实没有先看这个算子，而是去看了一遍整体的Deformable DETR的模型网络架构，了解到了我们的msda其实是位于可变型卷积之后的Transformer解码层（当然编码层也会有），我们上游其实已经将query的特征向量以及通道内容之类的都确定好了，所以这个msda其实是一个纯计算类算子。

针对这个算子，我首先看了一下他的流程，首先是Mul，然后会经过一个Sub，从NPU硬件视角来看，这个其实是由每一个tile的CVU来完成的，所以我跟锯DSL的CVU源语完成了这两个操作，之后会有Transpose操作，需要将两个轴进行调换，此时需要两条UtoU数据通线。这一操作是为了迎合后面的专用插值硬件IPU服务的，而IPU又是为了Transpose进行服务的。另外，由于考虑到了每个Tile的专属空间有限，我们对于batch轴和channel进行了切分，在Tile上使用了数据流水的方式（实际上这个切分策略是取决于上游的），最后因为我们要对最后的输出乘权重嘛，而又因为每个Tile是并行处理一个query的，而同一query的同一维乘的权重又是相同的，所以我们采用了tile间的scatter策略。

最后成功适配了上游的轴切分策略的变化，并将性能优化到了2ms

## deepseek的点评

我是面试官。听完你的回答，我有几个关键点需要澄清和深入追问。你的描述涉及了一些硬件细节，但整体逻辑的连贯性和技术深度还需要进一步挖掘。

首先，我注意到几个需要你澄清的地方：

你提到“从NPU硬件视角来看，这个其实是由每一个tile的CVU来完成的”——这里的CVU是计算向量单元吗？你能具体解释一下这个硬件计算单元的特性吗？

你提到了“两条UtoU数据通线”，这是什么？是NPU内部的数据总线吗？

“专用插值硬件IPU”是什么？它和Transpose操作有什么关系？

你说“切分策略是取决于上游的”，那么你具体做了哪些工作来“适配上游的轴切分策略的变化”？

现在，为了更深入地评估你的技术能力，我要问几个关键问题：

### 问题1：性能分析与量化

你说从9ms优化到2ms，这个数据是如何测量得到的？使用了什么性能分析工具？

在优化过程中，你如何定位到性能瓶颈？最初的9ms中，各部分操作（Mul、Sub、Transpose等）的时间分布是怎样的？

### 问题2：优化策略的权衡

你提到了对batch轴和channel进行切分。为什么选择这两个轴？有没有考虑过其他切分策略？比如对height或width进行切分？

在资源受限的Tile上，你如何平衡计算并行度和内存占用？有没有遇到过因Tile内存不足而需要调整切分策略的情况？

### 问题3：硬件细节理解

你提到的“tile间的scatter策略”具体是如何实现的？能否画一个简单的示意图说明数据流和权重的分布？

为什么同一query的同一维乘的权重相同？这是由算法决定的吗？这个特性如何帮助你的优化？

### 问题4：正确性验证

在如此激进的优化（9ms到2ms，约4.5倍加速）后，你是如何保证算子的数值正确性的？有没有做过精度测试？误差在什么范围内？

### 问题5：协作与沟通

这个优化任务中，你和上游（框架或模型团队）的协作是怎样的？你如何理解他们的需求并调整你的实现？

如果上游的切分策略发生了变化，你需要多长时间来适应这种变化？这种变化是经常发生的吗？